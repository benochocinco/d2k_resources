---
title: "Data Cleaning & Wrangling Example"
author: "D2K Course Staff"
date: "1/15/2019"
output: pdf_document
---

# Initial Working Example

## Load Data

```{r}
# Load libraries
library(dplyr)

# Read in drinks data set
drinks <- read.csv("data/drinks.csv", header = TRUE, stringsAsFactors = FALSE)

# Read in life expectancy data set
life_exp <- read.csv("data/lifeexpectancy.csv", header = TRUE, stringsAsFactors = FALSE)
```

## Clean Drinks Data

### Examine Dataset

We look at the head of the dataset in order to examine column names and get a sense of what the data looks like.

```{r}
head(drinks)
```

We can see that the far right column is empty. This is a variable that we will be calculating from other variables. However, we need to understand if there is any missing data in the columns we will be using to calculate total_litres_of_pure_alcohol.

```{r}
drinks[is.na(drinks[,2:4]),]
```

### Calculate new features from the data

We see that there are no NA values in our dataset, thus we continue and calculate the total_litres_of_pure_alchol by multiplying the number of servings of alcohol by the standard number of litres of pure alcohol per serving in order to calculate total consumption by country (https://www.niaaa.nih.gov/alcohol-health/overview-alcohol-consumption/what-standard-drink). 

```{r}
# Calculate total litres
drinks$total_litres_of_pure_alcohol <- (drinks$beer_servings + drinks$spirit_servings + drinks$wine_servings)*0.017744
```

Uh-oh! There must be something wrong with the data as it stands. Let us investigate further...

```{r}
summary(drinks)
```

Hmmm... it seems as if all of the variables we know to be numeric are of the type "character". Why could this be? At this point, it is important to look at the entire dataset to discover the discrepancy. We make an interesting observation...

```{r}
drinks[drinks[,2] == "?" | drinks[,3] == "?" | drinks[,4] == "?",]
```

We can see that missing values are represented by "?". When working with missing data it is important to represent it in a consistent way. We choose to replace the "?" with "NA" values as it makes it easier to work with in R. Additionally, we convert the columns to numeric now that we have removed the question marks that coerced the entire column into character.

```{r}
# Replace ? values with NA
drinks[drinks == "?"] <- NA

# Convert columns from character to numeric
drinks$beer_servings <- as.numeric(drinks$beer_servings)
drinks$spirit_servings <- as.numeric(drinks$spirit_servings)
drinks$wine_servings <- as.numeric(drinks$wine_servings)
```

Now we can calculate total_litres_of_pure_alcohol consumed for each country.

```{r}
# Calculate total litres
drinks$total_litres_of_pure_alcohol <- (drinks$beer_servings + drinks$spirit_servings + drinks$wine_servings)*0.017744
```

Let's examine what data is missing at this point...

```{r}
drinks[is.na(drinks$total_litres_of_pure_alcohol),]
```

Since we are only concerned with total alcohol consumption, we only have to worry about dealing with the missing data points in the total_litres_of_pure_alcohol column. There are many ways to deal with missing data, and there is no ideal way to deal with it, but we can do our best with what we have. Since alcohol consumption is publicly available data, we can find the missing data on the internet via a quick google search (https://data.worldbank.org/indicator/SH.ALC.PCAP.LI). Luckily, we are able to find supplementary data that we can combine with our initial dataset. Even though the 

For more about dealing with missing data, please check out the following resource: https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4.

```{r}
# Read in supplementary alcohol consumption dataset
consumption <- read.csv("data/alcohol_consumption.csv", header = TRUE, stringsAsFactors = FALSE, skip = 3)

head(consumption)
```

We can see that there are quite a few extra columns that are filled with NA values. In order to ween down the dataset we remove any column that is entirely populated with NA's.

```{r}
# Remove empty columns
consumption <- consumption[,colSums(is.na(consumption))<nrow(consumption)]
```

Since there are mulitple years of data, we want to make sure we only keep the most recent year since we followed that same logic previously in our wrangling process. We also keep only the country column and the most recent consumption column. 

```{r}
# Grab most recent year column
most_recent <- names(consumption)[ncol(consumption)]

# Rename country column and keep only country column and most recent year column
consumption <- consumption %>%
  rename(country = Country.Name, most_recent = most_recent) %>%
  select(country, most_recent)
```

We will need to join this supplementary data set with our original $drinks$ dataset. Before we can do that, we need to clean up the country names in order to perform a join on that column.

```{r}
# Remove parentheses, contents within, and space before
consumption$country <- gsub("\\s*\\([^\\)]+\\)", "", consumption$country)

# Remove anything after a comma
consumption$country <- gsub("(.*),.*", "\\1", consumption$country)

# Refactor country names for join with life expectancy data
consumption$country <- gsub("&", "and", consumption$country)
```

Finally, we can join the supplementary dataset and replace the missing values that we need, dropping the extra column after we take the data we need.

```{r}
# Replace missing data from supplementary consumption data
drinks <- drinks %>%
  left_join(consumption, by = "country") %>%
  mutate(total_litres_of_pure_alcohol = coalesce(total_litres_of_pure_alcohol, most_recent)) %>%
  select(-most_recent)
```

### Engineer features

An important part of creating your data pipeline and preparing your dataset for analysis is the engineering of features. Often, we find the most insight and draw the most important conclusions from features that were not explictly present in the original data. 

In this case, we create an indicator variable to represent whether the total alcohol consumption per capita is above the "healthy" threshold of alcohol consumption as determined by the NIH (https://www.niaaa.nih.gov/alcohol-health/overview-alcohol-consumption/what-standard-drink).

```{r}
# Engineer feature to create indicator variable of whether consumption is above or below 7 drinks per week
# Healthy consumption threshold = 0.017744 x 7 x 52 = 6.458816
drinks$unhealthy_consumption <- 0
drinks$unhealthy_consumption[drinks$total_litres_of_pure_alcohol > 6.458816] <- 1
```


## Clean Life Expectancy Data

### Examine Dataset

We look at the head of the dataset in order to examine column names and get a sense of what the data looks like.

```{r}
head(life_exp)
```

And get a summary of the variable types...

```{r}
summary(life_exp)
```

### Clean Life Expectancy Data

This data is not nearly as clean as the drinks data. We see that there are multiple observations for each country and many years of data contained in the dataset. We only want to look at the most up-to-date data, so we filter to only keep the rows for the year 2013.

Furthermore, there are many measures of life expectancy in the dataset! Since our drinks data is recorded for all citizens and not any specific gender, we only want to look at life expectancy data for *Both Sexes*.

```{r}
# Keep only most recent year's data
life_exp <- life_exp %>%
  filter(YearDisplay == max(life_exp$YearCode))

# Keep only the rows with life expectancy data for "Both sexes"
life_exp <- life_exp %>% 
  filter(SexDisplay == "Both sexes")

head(life_exp)
```

Additionally, we only want to keep the variables that are relevant to us for our analysis. Most datasets have columns that store extraneous or redundant information, just like in this dataset where we have multiple columns for country name/ID, year, continent, etc.

```{r}
# Select relevant columns to keep 
life_exp <- life_exp %>%
  select(GhoDisplay, YearDisplay, WorldBankIncomeGroupDisplay, CountryDisplay, SexDisplay, Numeric)

head(life_exp)
```

We also want to replace all of the missing values represented by empty strings as NA values so that they are easier to work with

```{r}
# Fill in missing values with NA
life_exp[life_exp == ""] <- NA

head(life_exp)
```

We notice that the missing data is for the World Bank Income level. Since this is a variable that we are interested in including in our final dataset, we need to make sure that we populate the missing values with the appropriate corresponding value for that country.

We can accomplish this by arranging the dataset by the $GhoDisplay$ and then fill in the missing values from the most recent values in the column.

```{r}
# Arrange alphabetically so NA values are below for each category to utilize fill function 
life_exp <- life_exp %>%
  arrange(CountryDisplay, GhoDisplay) %>%
  fill(WorldBankIncomeGroupDisplay, .direction = "down")

head(life_exp)
```

Also, there are still three different measures of life expectancy in our dataset. Which one is appropriate for the objective of our analysis? Since we are comparing total life expectancy with total per capita consumption of alcohol, we select the "Life expectancy at birth (years)" category as the relevant outcome variable. We filter the data to reflect this.

```{r}
# Keep life expectancy measure of interest
life_exp <- life_exp %>%
  filter(GhoDisplay == "Life expectancy at birth (years)")
```


Recall that the goal of the wrangling process is to tidy our data into a neat $n x p$ format where each row is an observation and each column is a relevant variable. However, we still have identifying variable columns that we don't actually want to include in our analysis. We will select the specific columns we want for our analysis and the country column to join with the drinks data. We can also rename the columns for easier reference later.

```{r}
# Select relevant columns and rename them
life_exp <- life_exp %>%
  select(CountryDisplay, WorldBankIncomeGroupDisplay, Numeric) %>%
  rename(country = CountryDisplay, income = WorldBankIncomeGroupDisplay, life_expectancy = Numeric)
```

### Generate Dummy Variables

One thing that we can observe from the above data is that one of our variables is a categorical variable. Different functions, models, tests, etc. in R work with different formulations of categorical data. Some of these perform fine when categorical data is stored in a single column that is of a "factor" variable type. However, many of these functions require all data to be numeric. We can represent these categorical variables numerically by generating dummy variables. In general, it is good to have datasets with both formulations of categorical variables so that you are able to call whichever one you need based on the analysis you are trying to perform. We can create both of these datasets below.

Note: when creating dummy variables remember that you must only create columns for $k-1$ categories to avoid issues with multicollinearity.

```{r}
# Create factor variable dataset
life_exp_factor <- life_exp
life_exp_factor$income <- as.factor(life_exp_factor$income)

# Create dummy variable dataset
dummys <- model.matrix(~life_exp_factor$income)
# Exclude last column of original dataset and intercept column of dummy variables
life_exp_dummy <- data.frame(life_exp_factor[,-ncol(life_exp_factor)], dummys[,-1])
```

## Join Datasets for Analysis

Now that we have cleaned both datasets, we want to combine them to create our final dataset for analysis. Unfortunately, we must join the two datasets on the name of the country. In general, joining on character strings is not ideal as there is much more room for variation compared to distinct ID's. However, data is rarely in the form that is ideal so we will work with what we have. We attempt to join the two datasets on the country names and observe the following match rate.

```{r}
# Join datasets and calculate match rate
model_data_factor <- left_join(life_exp_factor, drinks, by = "country")
match_rate_before <- sum(!is.na(model_data_factor$total_litres_of_pure_alcohol))/nrow(model_data_factor)
match_rate_before
```

This is not terrible considering we did not adust the country names at all before trying to join the two datasets. However, we can investigate the data and the names of the countries to figure out how we can match as much of the data as possible.

### Refactor Country Names

After inspecting the data (you can do this on your own), we notice a couple of things:

* The life expectancy data uses "_" instead of "-" in country names
* The life expectancy data uses full-length official country names which include text within parentheses
* The drinks data uses "&" and the life expectancy data uses "and"

We attempt to systematically adjust for these differences to the best of our ability and observe the new match rate.

```{r}
# Replace underscores with dashes
life_exp_factor$country <- gsub("_", "-", life_exp_factor$country)

# Remove parentheses, contents within, and space before
life_exp_factor$country <- gsub("\\s*\\([^\\)]+\\)", "", life_exp_factor$country)

# Replace Saint with St.
life_exp_factor$country <- gsub("Saint", "St.", life_exp_factor$country)

# Refactor country names for join with life expectancy data
drinks$country <- gsub("&", "and", drinks$country)

# Join datasets and calculate match rate
model_data_factor <- left_join(life_exp_factor, drinks, by = "country")
match_rate_sys <- sum(!is.na(model_data_factor$total_litres_of_pure_alcohol))/nrow(model_data_factor)
match_rate_sys
```

Still, we are only able to math ~92% of the data. Looking at the data more closely, it is clear this is just due to the discrepancies in how certain countries are referenced in each dataset. We can go through and manually adjust the name of each country so that we can match all of the data. We then calculate our final match rate. 

```{r}
# Hard-code country names to match drinks dataset, unfortunately this is unavoidable in this context
life_exp_factor$country[life_exp_factor$country == "Bosnia and Herzegovina"] <- "Bosnia-Herzegovina"
life_exp_factor$country[life_exp_factor$country == "Brunei Darussalam"] <- "Brunei"
life_exp_factor$country[life_exp_factor$country == "Côte d'Ivoire"] <- "Cote d'Ivoire"
life_exp_factor$country[life_exp_factor$country == "Democratic People's Republic of Korea"] <- "North Korea"
life_exp_factor$country[life_exp_factor$country == "Democratic Republic of the Congo"] <- "DR Congo"
life_exp_factor$country[life_exp_factor$country == "Lao People's Democratic Republic"] <- "Laos"
life_exp_factor$country[life_exp_factor$country == "Republic of Korea"] <- "South Korea"
life_exp_factor$country[life_exp_factor$country == "Republic of Moldova"] <- "Moldova"
life_exp_factor$country[life_exp_factor$country == "Syrian Arab Republic"] <- "Syria"
life_exp_factor$country[life_exp_factor$country == "The former Yugoslav republic of Macedonia"] <- "Macedonia"
life_exp_factor$country[life_exp_factor$country == "United Kingdom of Great Britain and Northern Ireland"] <- "United Kingdom"
life_exp_factor$country[life_exp_factor$country == "United Republic of Tanzania"] <- "Tanzania"
life_exp_factor$country[life_exp_factor$country == "United States of America"] <- "USA"
life_exp_factor$country[life_exp_factor$country == "Viet Nam"] <- "Vietnam"

# Join datasets and calculate match rate
model_data_factor <- left_join(life_exp_factor, drinks, by = "country")
match_rate_final <- sum(!is.na(model_data_factor$total_litres_of_pure_alcohol))/nrow(model_data_factor)
match_rate_final
```

Excellent! We have merged both datasets to the best of our ability. However, we still need to make sure that we don't have any incomplete data. Let's see what's still missing...

```{r}
model_data_factor[is.na(model_data_factor$total_litres_of_pure_alcohol),]
```

Ah! It looks like there is a country that exists in the life expectancy data set that does not exist in the drinks dataset. At this point, we are safe just removing this row from the dataset. 

```{r}
# Keep only rows without missing data
model_data_factor <- model_data_factor[!is.na(model_data_factor$total_litres_of_pure_alcohol),]
```

Now we have completed the data wrangling process! Wait! Except the life expectancy dataset we created earlier with dummy variables doesn't have any of the country names changes and thus won't be able to merge with the drinks dataset accurately as it currently stands. Since we have already typed this all out... we will just repeat the code. 

```{r}
# Create dummy variable dataset
dummys <- model.matrix(~life_exp_factor$income)

# Exclude last column of original dataset and intercept column of dummy variables
life_exp_dummy <- data.frame(life_exp_factor[,-ncol(life_exp_factor)], dummys[,-1])

# Join datasets
model_data_dummy <- left_join(life_exp_dummy, drinks, by = "country")

# Keep only rows without missing data
model_data_dummy <- model_data_dummy[!is.na(model_data_dummy$total_litres_of_pure_alcohol),]
```

Even though it was only 4 lines of code, this is still a practice we want to avoid. We NEVER want to repreat code if we can help it! 

## Conclusion

For the exploratory phase of data cleaning and wrangling, it is okay not to do everything perfectly and work through your logic in a markdown file such as this. However, when you are creating a data pipeline we want to modularize and functionalize as many things as possible. An R Markdown file is a great way to communicate analysis and results, but is a bad way to engineer your data pipeline as it cannot be called in the same fluid way that an R Script can be. We see an example of how to properly construct the pipeline in the next section.

# Proper Data Pipeline Example

Here we show an example of how we can build the data pipeline in R scripts and then source data cleaning and loading functions into the R Markdown file. Additionally, we write a script to automatically load all dependencies (i.e. libraries, packages) and install them if they are not already installed on the system running the code.

```{r}
# Source script to install/load dependencies
source("load_dependencies.R")

# Source cleaning_and_wrangling script
source("cleaning_and_wrangling.R")
```

## Load cleaned and wrangled datasets

As you can see, instead of working through all of the cleaning and wrangling process within R Markdown chunks, we just source our cleaning and wrangling scripts and call whatever function we need to get the appropriate data. This is a far better practice for ensuring reproducibility within your pipeline as different team members can load the data in the same way and then perform their own analyses individually without having to be concerned that their datasets are not the same. Furthermore, it is just way easier to read through and follow as opposed to aggregating every single piece of work that you did into one R Markdown file.

```{r}
# Load cleaned drinks dataset
drinks_clean <- clean_drinks("data/drinks.csv", "data/alcohol_consumption.csv")

# Load cleaned life expectancy dataset
life_exp_clean <- clean_life_exp("data/lifeexpectancy.csv")

# Load model dataset with categorical variable stored as factor
model_data_factor_clean <- load_factor_data("data/drinks.csv", "data/alcohol_consumption.csv", "data/lifeexpectancy.csv")

# Load model dataset with categorical variables stored as dummy variables
model_data_dummy_clean <- load_dummy_data("data/drinks.csv", "data/alcohol_consumption.csv", "data/lifeexpectancy.csv")
```

Now that we have our datasets loaded in nice and cleanly we can begin the next stage of our pipeline!


