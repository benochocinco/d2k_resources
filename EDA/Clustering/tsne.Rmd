---
title: "t-SNE Example"
author: "D2K Course Staff"
date: "`r format(Sys.time(), '%B %d %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
library(knitr) # We need the knitr package to set chunk options
library(ggplot2)

# Set default knitr options for knitting code into the report:
opts_chunk$set(echo=TRUE,  # change to FALSE to keep code out of the knitted document
               cache=FALSE, # re-run code that has already been run?
               autodep=TRUE, # assure that caching dependencies are updated correctly
               cache.comments=FALSE, # do not re-run a chunk if only comments are changed
               message=FALSE, # change to FALSE to keep messages out of the knitted document
               warning=FALSE,  # change to FALSE to keep warnings out of the knitted document
               comment = NA,
               tidy.opts=list(width.cutoff=65),
               fig.height = 5)

theme1 <- theme_bw() +
  theme(axis.text = element_text(size = 8, colour = "#6b3447"),
        axis.title = element_text(size = 10, colour = "#2f2f63"),
        legend.title = element_text(size = 8, colour = "#2f2f63"),
        legend.text = element_text(size = 8, colour = "#6b3447"), 
        title = element_text(size = 12, colour = "#2f2f63"), 
        axis.ticks = element_line(colour = "#6b3447"),
        plot.caption = element_text(size = 8, colour = "#2f2f63"),
        plot.subtitle = element_text(size = 10, colour = "#2f2f63"))
```

# Introduction

One of them newfangled clustering methods that all the cool stat kids are using these days is called t-SNE, which stands for t-Distributed Stochastic Neighbor Embedding. The main idea of t-SNE is to visualize our data in a low-dimensional space (by default 2 dimensions) while maintaining as much of the original high-dimensional structure as possible. This is measured by comparing a similarity score for the relative pairwise distances between points in the original data and in the low-dimensional representation.

## Disadvantages

This setup does have a couple of disdvantages:

1. Results can depend on the random starting values of $Y_i$ chosen.
2. The method does not actually assign points to clusters, in the same manner that your basic k-means or your convex clustering methods would. The idea here is just to find the low-dimenisonal representation that best maintains relative pairwise distances between the points. If we want to get automatically assigned clusters, we could then run a clustering algorithm on the low-dimensional representation returned by t-SNE.

## Math Stuff

For those that care about this sort of stuff, the math behind measuring similarity can be found at: 

https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf

As a quick and undetailed summary:

- We calculate the conditional probability that a point would call another point its "nearest neighbor" in the original dimensional space as proportional to the pairwise Euclidean distance between the points over the sum of all the distances between the points: $$p_{j|i} \propto \frac{\exp(-\|x_j - x_i \|^2)}{\sum_{k} \exp(-\|x_k - x_i \|^2)}.$$ This is done for all pairs of points.
- We calculate the conditional probability that a point would call another point its "nearest neighbor" in the low dimensional space in the same manner: $$q_{j|i} \propto \frac{\exp(-\|y_j - y_i \|^2)}{\sum_{k} \exp(-\|y_k - y_i \|^2)}.$$
- We attempt to find the set of $y_i$ that minimizes the KL divergence between the $p_{j|i}$ and $q_{j|i}$, where $$KL = \sum_i \sum_j p_{j|i} \log \frac{p_{j|i}}{q_{j|i}}.$$ Algorithmically, this can be done via gradient descent.


\newpage

# Example

In this example, we will analyze the `wine` data set from the `rattle.data` package. We will be clustering assuming that we do not know the wine type, and we will attempt to see if we can find different groups of wines in the data, perhaps to see if we can find classifications to ensure similar taste or composition amongst all wines of the same labeled type.

```{r}
library(rattle.data)
data(wine)
head(wine)
```

We will use the R package `Rtsne` to run t-SNE on the data. 

```{r}
library(Rtsne)
```

```{r}
set.seed(316)
mod1 <- Rtsne::Rtsne(wine[, -1])
```

```{r}
ggplot() +
  geom_point(aes(x = mod1$Y[, 1], y = mod1$Y[, 2],
                 color = wine$Type)) +
  labs(title = "t-SNE Results",
       x = "Dim 1", y = "Dim 2",
       color = "True Type") +
  theme1
```

As we can see from these results, there is a pretty clear cluster for the Type 1 wine. However, Types 2 and 3 seem to be too similar to discern in to separate types.

